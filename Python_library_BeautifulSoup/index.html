<!DOCTYPE html>
<html lang='zh-Hans'>

<head>
  <meta name="generator" content="Hexo 5.3.0">
  <meta charset="utf-8">
  

  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://fastly.jsdelivr.net'>
  <link rel="preconnect" href="https://fastly.jsdelivr.net" crossorigin>
  <link rel='dns-prefetch' href='//unpkg.com'>

  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  <title>Python库BeautifulSoup使用 - Sharp tools make good work</title>

  
    <meta name="description" content="BeautifulSoup概述 BeautifulSoup模块用于从HTML文本中提取我们想要的数据，参考网站：https:&#x2F;&#x2F;beautifulsoup.readthedocs.io&#x2F;zh_CN&#x2F;latest&#x2F;  BeautifulSoup 有多个版本，这里选择版本BeautifulSoup4。  模块安装，在命令行终端下使用命令： 123conda install beautifulsoup4">
<meta property="og:type" content="article">
<meta property="og:title" content="Python库BeautifulSoup使用">
<meta property="og:url" content="http://wangxianggit.github.io/Python_library_BeautifulSoup/index.html">
<meta property="og:site_name" content="Sharp tools make good work">
<meta property="og:description" content="BeautifulSoup概述 BeautifulSoup模块用于从HTML文本中提取我们想要的数据，参考网站：https:&#x2F;&#x2F;beautifulsoup.readthedocs.io&#x2F;zh_CN&#x2F;latest&#x2F;  BeautifulSoup 有多个版本，这里选择版本BeautifulSoup4。  模块安装，在命令行终端下使用命令： 123conda install beautifulsoup4">
<meta property="og:locale">
<meta property="article:published_time" content="2019-02-23T14:12:19.000Z">
<meta property="article:modified_time" content="2019-02-24T06:29:44.435Z">
<meta property="article:author" content="wangxiang">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="BeautifulSoup">
<meta name="twitter:card" content="summary">
  
  

  <!-- feed -->
  

  
    
<link rel="stylesheet" href="/css/main.css">

  

  

  
</head>

<body>
  




  <div class='l_body' id='start'>
    <aside class='l_left' layout='post'>
    


<header class="header">

<div class="logo-wrap"><a class="title" href="/"><div class="main">Sharp tools make good work</div><div class="sub cap">Open your minds</div></a></div>
<nav class="menu dis-select"></nav></header>

<div class="widgets">

<div class="widget-wrap single" id="toc"><div class="widget-header cap dis-select"><span class="name">本文目录</span></div><div class="widget-body fs14"><div class="doc-tree active"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#BeautifulSoup%E6%A6%82%E8%BF%B0"><span class="toc-text">BeautifulSoup概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95"><span class="toc-text">使用方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#BeautifulSoup%E5%AF%B9%E8%B1%A1%E7%B1%BB%E5%9E%8B"><span class="toc-text">BeautifulSoup对象类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tag"><span class="toc-text">Tag</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NavigableString"><span class="toc-text">NavigableString</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#BeautifulSoup"><span class="toc-text">BeautifulSoup</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Comment"><span class="toc-text">Comment</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BeautifulSopu%E9%81%8D%E5%8E%86%E6%B3%95"><span class="toc-text">BeautifulSopu遍历法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8A%82%E7%82%B9%E5%92%8C%E6%A0%87%E7%AD%BE%E5%90%8D"><span class="toc-text">节点和标签名</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%90%9C%E7%B4%A2%E6%96%87%E6%A1%A3%E6%A0%91"><span class="toc-text">搜索文档树</span></a></li></ol></li></ol></div></div></div>


</div>


    </aside>
    <div class='l_main'>
      

      

<div class="bread-nav fs12"><div id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a><span class="sep"></span><a class="cap breadcrumb" href="/">文章</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/Python/">Python</a></div><div id="post-meta">发布于&nbsp;<time datetime="2019-02-23T14:12:19.000Z">2019-02-23</time></div></div>

<article class='content md post'>
<h1 class="article-title"><span>Python库BeautifulSoup使用</span></h1>
<h2 id="BeautifulSoup概述"><a href="#BeautifulSoup概述" class="headerlink" title="BeautifulSoup概述"></a>BeautifulSoup概述</h2><ul>
<li><p>BeautifulSoup模块用于从HTML文本中提取我们想要的数据，参考网站：<a target="_blank" rel="noopener" href="https://beautifulsoup.readthedocs.io/zh_CN/latest/">https://beautifulsoup.readthedocs.io/zh_CN/latest/</a></p>
</li>
<li><p>BeautifulSoup 有多个版本，这里选择版本BeautifulSoup4。</p>
</li>
<li><p>模块安装，在命令行终端下使用命令：</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda install beautifulsoup4 <span class="regexp">//</span>前提安装了anaconda</span><br><span class="line">或使用pip命令</span><br><span class="line">pip install beautifulsoup4 </span><br></pre></td></tr></table></figure></li>
<li><p>lxml是一个解析器，BeautifulSoup可以使用它来解析HTML，然后提取内容，模块安装</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda <span class="keyword">install</span> lxml</span><br></pre></td></tr></table></figure>
<ul>
<li>如果不安装lxml，则BeautifulSoup会使用Python内置的解析器对文档进行解析。之所以使用lxml，是因为它速度快。</li>
</ul>
</li>
<li><p>不同文档解析器对比如下：</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>解析器</th>
<th>使用方法</th>
<th>优势</th>
<th>劣势</th>
</tr>
</thead>
<tbody><tr>
<td>Python标准库</td>
<td>BeautifulSoup(markup,”html.parser”)</td>
<td>Python的内置标准库  执行速度适  中文档容错能力强</td>
<td>Python 2.7.3 or 3.2.2)前 的版本中文档容错能力差</td>
</tr>
<tr>
<td>lxml HTML 解析器</td>
<td>BeautifulSoup(markup,”lxml”)</td>
<td>速度快  文档容错能力强</td>
<td>需要安装C语言库</td>
</tr>
<tr>
<td>lxml XML 解析器</td>
<td>BeautifulSoup(markup,[“lxml-xml”]) BeautifulSoup(markup,”xml”)</td>
<td>速度快  唯一支持XML的解析器</td>
<td>需要安装C语言库</td>
</tr>
<tr>
<td>html5lib</td>
<td>BeautifulSoup(markup,”html5lib”)</td>
<td>最好的容错性  以浏览器的方式解析文档  生成HTML5格式的文档</td>
<td>速度慢，不依赖外部扩展</td>
</tr>
</tbody></table>
<h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><h3 id="BeautifulSoup对象类型"><a href="#BeautifulSoup对象类型" class="headerlink" title="BeautifulSoup对象类型"></a>BeautifulSoup对象类型</h3><ul>
<li>BeautifulSoup将复杂HTML文档转换成一个复杂的树形结构，每个节点都是Python对象。</li>
<li>所有对象可以归纳为4种类型: Tag , NavigableString , BeautifulSoup , Comment 。</li>
</ul>
<h3 id="Tag"><a href="#Tag" class="headerlink" title="Tag"></a>Tag</h3><ul>
<li><p>Python中的Tag和HTML或XML中的标签一样。</p>
</li>
<li><p>使用find()方法返回的类型就是Tag，用find_all()返回的是多个Tag对象的集合，在Python中可以用for循环遍历。</p>
</li>
<li><p>返回Tag后，可以提取该对象中包含的信息。</p>
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">tag</span>.name /提取标签名字</span><br><span class="line"><span class="keyword">tag</span>[&#x27;<span class="keyword">attribute</span>&#x27;] /提取标签的属性</span><br></pre></td></tr></table></figure>
<ul>
<li>示例代码：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">from bs4 import BeautifulSoup</span><br><span class="line"></span><br><span class="line">html_doc = <span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;</span>title<span class="string">&quot;&gt;&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;</span>story<span class="string">&quot;&gt;Once upon a time there were three little sisters; and their names were</span></span><br><span class="line"><span class="string">&lt;a href=&quot;</span>http://example.com/elsie<span class="string">&quot; class=&quot;</span>sister<span class="string">&quot; id=&quot;</span>link1<span class="string">&quot;&gt;Elsie&lt;/a&gt;,</span></span><br><span class="line"><span class="string">&lt;a href=&quot;</span>http://example.com/lacie<span class="string">&quot; class=&quot;</span>sister<span class="string">&quot; id=&quot;</span>link2<span class="string">&quot;&gt;Lacie&lt;/a&gt; and</span></span><br><span class="line"><span class="string">&lt;a href=&quot;</span>http://example.com/tillie<span class="string">&quot; class=&quot;</span>sister<span class="string">&quot; id=&quot;</span>link3<span class="string">&quot;&gt;Tillie&lt;/a&gt;;</span></span><br><span class="line"><span class="string">and they lived at the bottom of a well.&lt;/p&gt;</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">&lt;p class=&quot;</span>story<span class="string">&quot;&gt;...&lt;/p&gt;</span></span><br><span class="line"><span class="string">&quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line">soup = BeautifulSoup(html_doc, <span class="string">&#x27;lxml&#x27;</span>)  <span class="comment">#声明BeautifulSoup对象</span></span><br><span class="line">find = soup.find(<span class="string">&#x27;p&#x27;</span>)  <span class="comment">#使用find方法查到第一个p标签</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;find&#x27;s return type is &quot;</span>, <span class="built_in">type</span>(find))  <span class="comment">#输出返回值类型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;find&#x27;s content is&quot;</span>, find)  <span class="comment">#输出find获取的值</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;find&#x27;s Tag Name is &quot;</span>, find.name)  <span class="comment">#输出标签的名字</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;find&#x27;s Attribute(class) is &quot;</span>, find[<span class="string">&#x27;class&#x27;</span>])  <span class="comment">#输出标签的class属性值</span></span><br></pre></td></tr></table></figure>
<h3 id="NavigableString"><a href="#NavigableString" class="headerlink" title="NavigableString"></a>NavigableString</h3></li>
</ul>
</li>
<li><p>NavigableString即是标签中的文本内容，获取方式如下：</p>
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">tag</span>.<span class="keyword">string</span></span><br></pre></td></tr></table></figure>
<ul>
<li>上面例子中使用上面获取之后得到的文本内容为：The Dormouse’s story</li>
</ul>
</li>
</ul>
<h3 id="BeautifulSoup"><a href="#BeautifulSoup" class="headerlink" title="BeautifulSoup"></a>BeautifulSoup</h3><ul>
<li>BeautifulSoup对象表示一个文档的全部内容。</li>
<li>可以支持遍历文档树和搜索文档树。</li>
<li>例如上面例子中的soup对象即为BeautifulSoup对象。</li>
</ul>
<h3 id="Comment"><a href="#Comment" class="headerlink" title="Comment"></a>Comment</h3><ul>
<li><p>该对象即为HTML或XML文档中的注释。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">markup = &quot;<span class="tag">&lt;<span class="name">b</span>&gt;</span><span class="comment">&lt;!--Hey, buddy. Want to buy a used parser?--&gt;</span><span class="tag">&lt;/<span class="name">b</span>&gt;</span>&quot;</span><br><span class="line">soup = BeautifulSoup(markup)</span><br><span class="line">comment = soup.b.string</span><br><span class="line">type(comment)</span><br><span class="line">\# <span class="tag">&lt;<span class="name">class</span> &#x27;<span class="attr">bs4.element.Comment</span>&#x27;&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>该类对象可以用来获取注释的内容，获取方法为：comment.string</p>
</li>
<li><p>可以用于判断该类型是否是一个注释</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">type</span>(SomeString) == bs4.element.Comment:</span><br><span class="line">    print(<span class="string">&#x27;该字符是注释&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">&#x27;该字符不是注释&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="BeautifulSopu遍历法"><a href="#BeautifulSopu遍历法" class="headerlink" title="BeautifulSopu遍历法"></a>BeautifulSopu遍历法</h2></li>
</ul>
<h3 id="节点和标签名"><a href="#节点和标签名" class="headerlink" title="节点和标签名"></a>节点和标签名</h3><ul>
<li><p>可以使用子节点、父节点及标签名的方式遍历：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">soup.head <span class="comment">#查找head标签</span></span><br><span class="line">soup.p <span class="comment">#查找第一个p标签</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#对标签的直接子节点进行循环</span></span><br><span class="line">title_tag=soup.find(<span class="string">&#x27;p&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> title_tag.children:</span><br><span class="line">    print(child)</span><br><span class="line"></span><br><span class="line">soup.parent <span class="comment">#父节点</span></span><br><span class="line"></span><br><span class="line">\<span class="comment"># 所有父节点</span></span><br><span class="line"><span class="keyword">for</span> parent <span class="keyword">in</span> link.parents:</span><br><span class="line">    <span class="keyword">if</span> parent <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        print(parent)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(parent.name)</span><br><span class="line"></span><br><span class="line">\<span class="comment"># 兄弟节点</span></span><br><span class="line">sibling_soup.b.next_sibling <span class="comment">#后面的兄弟节点</span></span><br><span class="line">sibling_soup.c.previous_sibling <span class="comment">#前面的兄弟节点</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#所有兄弟节点</span></span><br><span class="line"><span class="keyword">for</span> sibling <span class="keyword">in</span> soup.a.next_siblings:</span><br><span class="line">    print(<span class="built_in">repr</span>(sibling))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> sibling <span class="keyword">in</span> soup.find(<span class="built_in">id</span>=<span class="string">&quot;link3&quot;</span>).previous_siblings:</span><br><span class="line">    print(<span class="built_in">repr</span>(sibling))</span><br></pre></td></tr></table></figure>
<h3 id="搜索文档树"><a href="#搜索文档树" class="headerlink" title="搜索文档树"></a>搜索文档树</h3></li>
<li><p>常用的方法为find()和find_all(),其他的搜索方法有find_parent() 和 find_parents()、 find_next_sibling() 和 find_next_siblings() 、find_all_next() 和 find_next()、find_all_previous() 和 find_previous() 等。</p>
</li>
<li><p>find_all():搜索当前tag的所有tag子节点，并判断是否符合过滤器的条件。</p>
<ul>
<li>返回值类型是bs4.element.ResultSet</li>
<li>完整的语法：<code>find_all(name,attrs,recursive,string,**kwargs)</code></li>
<li>示例代码<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">     soup.find_all(<span class="string">&quot;title&quot;</span>)</span><br><span class="line">     # <span class="meta">[&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;]</span></span><br><span class="line">     #</span><br><span class="line">     soup.find_all(<span class="string">&quot;p&quot;</span>, <span class="string">&quot;title&quot;</span>)</span><br><span class="line">        # <span class="meta">[&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;&lt;/p&gt;]</span></span><br><span class="line">     # </span><br><span class="line">     soup.find_all(<span class="string">&quot;a&quot;</span>)</span><br><span class="line">     # <span class="meta">[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,</span></span><br><span class="line"><span class="meta">     #  &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;,</span></span><br><span class="line"><span class="meta">     #  &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;]</span></span><br><span class="line">     #</span><br><span class="line">     soup.find_all(id=<span class="string">&quot;link2&quot;</span>)</span><br><span class="line">     # <span class="meta">[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;]</span></span><br><span class="line">     #</span><br><span class="line">     import re</span><br><span class="line">     soup.find(string=re.compile(<span class="string">&quot;sisters&quot;</span>))</span><br><span class="line">     # u&#x27;Once upon a time there were three little sisters; <span class="keyword">and</span> their names were\n&#x27;</span><br><span class="line">     </span><br><span class="line">name 参数：可以查找所有名字为 name 的tag。</span><br><span class="line">attr 参数：就是tag里的属性。</span><br><span class="line">string 参数：搜索文档中字符串的内容。</span><br><span class="line">recursive 参数： 调用tag的 find_all() 方法时，Beautiful Soup会检索当前tag的所有子孙节点。如果只想搜索tag的直接子节点，可以使用参数 recursive=False 。</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>find():和find_all()类似，只是返回第一个值，返回类型为bs4.element.Tag。</p>
</li>
<li><p>完整语法为：<code>find(name,attrs,recursive,string,**kwargs)</code></p>
</li>
<li><p>示例代码</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">soup.find(<span class="string">&#x27;title&#x27;</span>)</span><br><span class="line">\# &lt;title&gt;The Dormous<span class="string">e&#x27;s story&lt;/title&gt;</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">soup.find(&quot;head&quot;).find(&quot;title&quot;)</span></span><br><span class="line"><span class="string">\# &lt;title&gt;The Dormouse&#x27;</span>s story&lt;/title&gt;</span><br></pre></td></tr></table></figure></li>
<li><p>以上代码在python3下运行，其他函数参看官方文档。</p>
</li>
</ul>
<hr>
<p>2019.2.23</p>


<div class="article-footer reveal fs14"><section id="license"><div class="header"><span>许可协议</span></div><div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div></section></div>

</article>

<div class="related-wrap reveal" id="read-next"><section class="header cap theme"><span>接下来阅读</span></section><section class="body fs14"><a id="next" href="/Markdown_add_table/">Markdown插入表格<span class="note">较早</span></a><div class="line"></div><a id="prev" href="/python_crawler/">python爬虫综述<span class="note">较新</span></a></section></div>








      
<footer class="page-footer reveal fs12"><hr><div class="text"><p>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p>
<p>本站由 <a href="http://wangxianggit.github.io/">@wangxiang</a> 创建，使用 <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.8.0" title="v1.8.0">Stellar</a> 作为主题。</p>
</div></footer>

      <div class='float-panel mobile-only blur' style='display:none'>
  <button type='button' class='sidebar-toggle mobile' onclick='sidebar.toggle()'>
    <svg class="icon" style="width: 1em; height: 1em;vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15301"><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 2.3 26.8 24.6 47.5 51.6 47.6h416.5v4z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15302"></path><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 1.9 27.7 23.9 49.7 51.6 51.6h416.5z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15303"></path></svg>
  </button>
</div>

    </div>
  </div>
  <div class='scripts'>
    <script type="text/javascript">
  stellar = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    loadCSS: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    // 从 butterfly 和 volantis 获得灵感
    loadScript: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    // https://github.com/jerryc127/hexo-theme-butterfly
    jQuery: (fn) => {
      if (typeof jQuery === 'undefined') {
        stellar.loadScript(stellar.plugins.jQuery).then(fn)
      } else {
        fn()
      }
    }
  };
  stellar.github = 'https://github.com/xaoxuu/hexo-theme-stellar/tree/1.8.0';
  stellar.config = {
    date_suffix: {
      just: '刚刚',
      min: '分钟前',
      hour: '小时前',
      day: '天前',
      month: '个月前',
    },
  };

  // required plugins (only load if needs)
  stellar.plugins = {
    jQuery: 'https://fastly.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js',
    sitesjs: '/js/plugins/sites.js',
    friendsjs: '/js/plugins/friends.js',
  };

  // optional plugins
  if ('true' == 'true') {
    stellar.plugins.lazyload = Object.assign({"enable":true,"js":"https://fastly.jsdelivr.net/npm/vanilla-lazyload@17.3.1/dist/lazyload.min.js","transition":"blur"});
  }
  if ('true' == 'true') {
    stellar.plugins.swiper = Object.assign({"enable":true,"css":"https://unpkg.com/swiper@6/swiper-bundle.min.css","js":"https://unpkg.com/swiper@6/swiper-bundle.min.js"});
  }
  if ('' == 'true') {
    stellar.plugins.scrollreveal = Object.assign({"enable":null,"js":"https://fastly.jsdelivr.net/npm/scrollreveal@4.0.9/dist/scrollreveal.min.js","distance":"8px","duration":500,"interval":100,"scale":1});
  }
  if ('true' == 'true') {
    stellar.plugins.preload = Object.assign({"enable":true,"service":"flying_pages","instant_page":"https://fastly.jsdelivr.net/gh/volantis-x/cdn-volantis@4.1.2/js/instant_page.js","flying_pages":"https://fastly.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.fancybox = Object.assign({"enable":true,"js":"https://fastly.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.umd.js","css":"https://fastly.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.css","selector":".swiper-slide img"});
  }
  if ('false' == 'true') {
    stellar.plugins.heti = Object.assign({"enable":false,"css":"https://unpkg.com/heti/umd/heti.min.css","js":"https://unpkg.com/heti/umd/heti-addon.min.js"});
  }
</script>

<!-- required -->

  
<script src="/js/main.js" async></script>



<!-- optional -->



<!-- inject -->


  </div>
</body>
</html>
